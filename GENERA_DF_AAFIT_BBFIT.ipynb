{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK PARA GENERAR EL DATAFRAME CON LA DATA DE TODOS LOS ARCHIVOS PARA AAFIT, BBFIT Y OTROS\n",
    "\n",
    "<font size=5>La data para los hits la generaré con otro Notebook.</font>\n",
    "\n",
    "Es importante mencionar que esta \"limpieza\" (generación del algoritmo) y obtención de data, me llevó aproximadamente 12 horas en general, desde el proceso creativo, pasando por la frustración, muchos intentos fallidos y hasta el momento de EUREKA!!!... XD.\n",
    "\n",
    "Borré ya la mayoría de celdas que me llevaron al código de las siguientes dos celdas, el cual está mucho más pulido y limpio, pero creo que es importente mencionar por lo que pase y las ideas (algunas locas) que me surgieron para poder resolverlo.\n",
    "\n",
    "Algunos ideas que tuve antes de llegar a decidir que no calcularia como tal el indice de aafit fueron:\n",
    "* Solo quedarme con los archivos que tuvieran 100% data completa (terrible idea ya que son más del 50% los archivos que en algunos eventos - alrededor del 5% o menos - no tienen data de aafit).\n",
    "* Verificar las longitudes de la cadena aafit y bbfit y comparar (idea bastante mala por cierto)\n",
    "* Tratar de buscar por separado en otra celda solo la data de aafit y \"pegarla\" de alguna manera al dataframe final, hay que decir que esta idea también fué muy mala y no prosperó en lo absoluto (creo no tenia ni pies ni cabeza, momento de frustración máxima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recordando algunas variables importantes, funciones y librerías que se requerirán\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "#extractpath = \"U:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\TXTs\" #Este path es para mi laptop en casa\n",
    "#extractpath = \"F:\\\\DATA_TFM\\\\TXTs\" #Este path es para mi PC en el trabajo\n",
    "extractpath = \"Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\TXTs\" #Este es para mi no tan nueva PC-Desktop\n",
    "\n",
    "txtfilesarr = os.listdir(extractpath); txtfilesarr=sorted(txtfilesarr)\n",
    "#csv_path = \"F:\\\\DATA_TFM\\\\CSVs\\\\\"\n",
    "csv_path = \"Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\\\\"\n",
    "csvarr = os.listdir(csv_path);csvarr=sorted(csvarr)\n",
    "\n",
    "# Funcion para obtener los indices de un archivo\n",
    "def indices(df):\n",
    "    ind_startev = [];ind_runid = [];ind_weights = [];ind_muon = []\n",
    "    ind_bbfit = [];ind_bb_selp = [];ind_endev = [];#ind_aafit = []\n",
    "    for i in range(data.shape[0]):\n",
    "        tempstr = data[0][i]\n",
    "        if \"start_event\" in tempstr: ind_startev.append(i)\n",
    "        if \"UTC\" in tempstr: ind_runid.append(i)\n",
    "        if \"weights\" in tempstr: ind_weights.append(i)\n",
    "        if \"muon\" in tempstr: ind_muon.append(i)\n",
    "        #if \"aafit\" in tempstr:  ##NO LO CALCULARE!!! OBTENDRE LOS VALORES DE OTRA FORMA\n",
    "        #    ind_aafit.append(i) ##COMO TENGO EL INDICE DE BBFIT, RESTO 1 LINEA Y ASIGNO VALORES\n",
    "        if \"bbfit\" in tempstr:   ##SEGUN LA EXISTENCIA O NO DE LA LINEA!!!! EUREKA!!!\n",
    "            ind_bbfit.append(i)\n",
    "        if \"selected\" in tempstr: ind_bb_selp.append(i)\n",
    "        if \"end_event\" in tempstr: ind_endev.append(i)\n",
    "    return(ind_startev,ind_runid,ind_weights,ind_muon,ind_bbfit,ind_bb_selp,ind_endev)\n",
    "\n",
    "#Función para verificar si los indices tienen el mismo # de elementos\n",
    "def longitudes(i1,i2,i3,i4,i5,i6,i7):\n",
    "    a=len(i1);b=len(i2);c=len(i3);d=len(i4);e=len(i5);f=len(i6);g=len(i7)\n",
    "    #print(a,b,c,d,e,f,g)\n",
    "    if (a==b and b==c and c==d and d==e and e==f and f==g): return(True)\n",
    "    else: return(False)\n",
    "    return()\n",
    "\n",
    "### NOTA: Como siempre, la gran cuestión y prerrogativa humana es encontrar patrones en los datos y automatizar\n",
    "### búsquedas aún y cuando estos no se vean a simple vista o no sean fácilmente inferibles, tales como cuando \n",
    "### el patrón es precisamente eso... que NO HAY PATRÓN!!!, esto aplica para el no indice ind_aafit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025800_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025800_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025880_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025880_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025920_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025920_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025930_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025930_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025990_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_025990_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026010_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026010_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026030_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026030_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026110_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026110_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026160_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026160_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026190_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026190_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026230_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026230_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026270_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026270_numu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "El archivo trabajando es:  Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CSVs\\MC_026340_anumu_CC_a_reco.i3.csv\n",
      "Entrando al bucle para meter renglones al dataframe\n",
      "Fin de la extracción de la data\n"
     ]
    }
   ],
   "source": [
    "############################################################################################################\n",
    "###### ESTE CODIGO GENERARÁ UN DATAFRAME CON LA DATA DE BBFIT, AAFIT Y OTRAS DE \"\"TODOS\"\" LOS ARCHIVOS #####\n",
    "############################################################################################################\n",
    "\n",
    "#Se requiere un dataframe donde iremos guardando cada fila de data obtenida de cada archivo\n",
    "columnas = ['runID','frameID','trigger_counter','interactionID','aafit_azimut',\n",
    "            'aafit_zenit','aafit_lambda','aafit_beta','bbfit_azimut','bbfit_zenit','bbfit_quality',\n",
    "            'muon_azimut','muon_zenit','muon_energy'] #La data del muon la añadi el 30 Jun, lo habia \"olvidado\" XD\n",
    "df_data1 = pd.DataFrame(columns=columnas)\n",
    "\n",
    "consecutivo=0 #variable auxiliar para guardar el indice del ultimo elemento del archivo\n",
    "\n",
    "# Bucle para recorrer TODOS los archivos y obtener la data y metadata de TODOS\n",
    "for k in range(25): #len(csvarr))\n",
    "    #print(\"Ciclo\", k)\n",
    "    file = csv_path+csvarr[k]\n",
    "    print(\"El archivo trabajando es: \",file)\n",
    "    data = pd.read_csv(file, header=None) # Dataframe del archivo en tratamiento\n",
    "    ind_startev = [];ind_runid = [];ind_weights = [];ind_muon = []\n",
    "    ind_bbfit = [];ind_bb_selp = [];ind_endev = []\n",
    "\n",
    "    #Generacion de indices para cada archivo\n",
    "    ind_startev,ind_runid,ind_weights,ind_muon,ind_bbfit,ind_bb_selp,ind_endev = indices(data)\n",
    "\n",
    "    #Como el runid es identico para todos los datos en un mismo archivo, uso el primero que aparece en el dataframe\n",
    "    runID = int(list(str(data[0][ind_runid[0]]).split(\" \"))[0])\n",
    "    #Igual como el interactionID es el mismo para todos, asigno 1 si el archivo es \"numu\" y 2 si es \"anumu\"\n",
    "    interactionID = [lambda:1, lambda:2][\"anumu\" in str(file)]()\n",
    "    # Bucle para recorrer el archivo en curso y obtener la data relevante\n",
    "    print(\"Entrando al bucle para meter renglones al dataframe\") \n",
    "    for i in range(len(ind_startev)):\n",
    "        #Codigo para obtener los demas datos por cada evento y despues asignarlo a los hits\n",
    "        #Divido la cadena en los valores que la componen para después extraer frameid y trigger_counter\n",
    "        temprunid = list(data[0][ind_runid[i]].split(\" \"))\n",
    "        tempmuon = list(data[0][ind_muon[i]].split(\" \"))\n",
    "        tempbbfit = list(data[0][ind_bbfit[i]].split(\" \"))\n",
    "        #Extrayendo las variables frameid, trigger_counter de este renglon---> esta data si cambia ojo!!\n",
    "        frameID = temprunid[1]; trigger_counter = temprunid [2]\n",
    "        #Obteniendo y generando Datos para aafit\n",
    "        #Para calcular la data solo haremos la diferencia y si exista data la calculamos si no\n",
    "        #pues ponemos valores fuera de rango para saber después que no hubo data como -3pi\n",
    "        laafit = data[0][ind_bbfit[i]-1]\n",
    "        if \"aafit\" in laafit:\n",
    "            tempaafit = list(data[0][ind_bbfit[i]-1].split(\" \"))\n",
    "            aafit_azimut = math.atan2(float(tempaafit[3]),float(tempaafit[2]))\n",
    "            aafit_zenit = math.acos(float(tempaafit[4]))\n",
    "            aafit_lambda = tempaafit[-2]\n",
    "            aafit_beta = tempaafit [-1]\n",
    "        else:\n",
    "            aafit_azimut=-3*math.pi;aafit_zenit = -3*math.pi;aafit_lambda=1;aafit_beta=-1\n",
    "        #Obteniendo y generando Datos para bbfit\n",
    "        X = float(tempbbfit[2]); Y = float(tempbbfit[3]); Z = float(tempbbfit[4])\n",
    "        #Hay que verificar si X o Y son nan y asignar el valor de bbfit_azimut\n",
    "        if math.isnan(X):   bbfit_azimut = -3*math.pi\n",
    "        elif math.isnan(Y): bbfit_azimut = -3*math.pi\n",
    "        else: bbfit_azimut = math.atan2(Y,X)\n",
    "        bbfit_zenit = math.acos(Z)\n",
    "        bbfit_quality = float(tempbbfit[-1]) \n",
    "        #Obteniendo y generando la data del muon\n",
    "        X = float(tempmuon[1]); Y = float(tempmuon[2]); Z = float(tempmuon[3])\n",
    "        muon_azimut = math.atan2(Y,X)\n",
    "        muon_zenit = math.acos(Z)\n",
    "        muon_energy = float(tempmuon[-2])\n",
    "        #Añadimos la data obtenida y la generada al dataframe\n",
    "        renglon = [runID, frameID, trigger_counter, interactionID,aafit_azimut, aafit_zenit,\n",
    "                   aafit_lambda,aafit_beta, bbfit_azimut,bbfit_zenit,bbfit_quality,muon_azimut,muon_zenit,muon_energy]\n",
    "        #Añadiendo datos al dataframe.\n",
    "        df_data1.loc[i+consecutivo] = renglon\n",
    "    consecutivo = df_data1.shape[0]\n",
    "\n",
    "    #consecutivo=i+1 #Sumar 1 es muy importante si no, sobreescribe el ultimo valor del evento, del archivo respectivo\n",
    "print(\"Fin de la extracción de la data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de filas del dataframe es: 5155\n",
      "Una muestra de las filas y la data en ellas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>runID</th>\n",
       "      <th>frameID</th>\n",
       "      <th>trigger_counter</th>\n",
       "      <th>interactionID</th>\n",
       "      <th>aafit_azimut</th>\n",
       "      <th>aafit_zenit</th>\n",
       "      <th>aafit_lambda</th>\n",
       "      <th>aafit_beta</th>\n",
       "      <th>bbfit_azimut</th>\n",
       "      <th>bbfit_zenit</th>\n",
       "      <th>bbfit_quality</th>\n",
       "      <th>muon_azimut</th>\n",
       "      <th>muon_zenit</th>\n",
       "      <th>muon_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>25990</td>\n",
       "      <td>110171</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.423677</td>\n",
       "      <td>-6.45441076961</td>\n",
       "      <td>0.0154777204448</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>0.412248</td>\n",
       "      <td>1.313463</td>\n",
       "      <td>0.026999</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>24.8090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>25920</td>\n",
       "      <td>9979</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.926711</td>\n",
       "      <td>0.839339</td>\n",
       "      <td>-6.34336377532</td>\n",
       "      <td>0.123222929322</td>\n",
       "      <td>2.531700</td>\n",
       "      <td>1.229617</td>\n",
       "      <td>2.934493</td>\n",
       "      <td>-2.463634</td>\n",
       "      <td>0.349742</td>\n",
       "      <td>333.7690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>26190</td>\n",
       "      <td>140849</td>\n",
       "      <td>275</td>\n",
       "      <td>2</td>\n",
       "      <td>1.381038</td>\n",
       "      <td>1.010685</td>\n",
       "      <td>-5.90871984937</td>\n",
       "      <td>0.0261208876628</td>\n",
       "      <td>2.246594</td>\n",
       "      <td>1.483662</td>\n",
       "      <td>1.865748</td>\n",
       "      <td>2.011759</td>\n",
       "      <td>1.499025</td>\n",
       "      <td>7039.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>25930</td>\n",
       "      <td>97351</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>0.911531</td>\n",
       "      <td>0.714967</td>\n",
       "      <td>-5.58818350355</td>\n",
       "      <td>0.00798197815014</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>0.656172</td>\n",
       "      <td>0.960881</td>\n",
       "      <td>1.071556</td>\n",
       "      <td>0.725642</td>\n",
       "      <td>7939.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>25920</td>\n",
       "      <td>78911</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>2.337692</td>\n",
       "      <td>1.159702</td>\n",
       "      <td>-6.2470896742</td>\n",
       "      <td>0.0407885708822</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>1.184103</td>\n",
       "      <td>6.608104</td>\n",
       "      <td>2.625332</td>\n",
       "      <td>1.755859</td>\n",
       "      <td>207.8210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>25920</td>\n",
       "      <td>125919</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.382817</td>\n",
       "      <td>0.356283</td>\n",
       "      <td>-5.50046034996</td>\n",
       "      <td>0.0136745911615</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>0.256969</td>\n",
       "      <td>0.645198</td>\n",
       "      <td>-0.352943</td>\n",
       "      <td>0.291665</td>\n",
       "      <td>19.8327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>26340</td>\n",
       "      <td>30781</td>\n",
       "      <td>125</td>\n",
       "      <td>2</td>\n",
       "      <td>2.316448</td>\n",
       "      <td>1.273985</td>\n",
       "      <td>-5.52610126548</td>\n",
       "      <td>0.0108518854219</td>\n",
       "      <td>2.323447</td>\n",
       "      <td>1.246598</td>\n",
       "      <td>1.186672</td>\n",
       "      <td>2.305526</td>\n",
       "      <td>1.269835</td>\n",
       "      <td>215.0780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>25990</td>\n",
       "      <td>53483</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.455953</td>\n",
       "      <td>0.406044</td>\n",
       "      <td>-5.31446152589</td>\n",
       "      <td>0.00926182047559</td>\n",
       "      <td>-2.382000</td>\n",
       "      <td>0.393877</td>\n",
       "      <td>0.553995</td>\n",
       "      <td>-1.988018</td>\n",
       "      <td>0.397162</td>\n",
       "      <td>102.2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>26340</td>\n",
       "      <td>23365</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.606926</td>\n",
       "      <td>0.690241</td>\n",
       "      <td>-4.8832394884</td>\n",
       "      <td>0.00826000187661</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>0.619391</td>\n",
       "      <td>1.577757</td>\n",
       "      <td>-1.613415</td>\n",
       "      <td>0.698633</td>\n",
       "      <td>57.1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>26030</td>\n",
       "      <td>51043</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>-9.424778</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.685443</td>\n",
       "      <td>1.499144</td>\n",
       "      <td>4.044593</td>\n",
       "      <td>-2.203849</td>\n",
       "      <td>2.262202</td>\n",
       "      <td>9111.8300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      runID frameID trigger_counter interactionID  aafit_azimut  aafit_zenit  \\\n",
       "2076  25990  110171              19             1      0.008170     0.423677   \n",
       "1114  25920    9979             143             2     -2.926711     0.839339   \n",
       "3562  26190  140849             275             2      1.381038     1.010685   \n",
       "1699  25930   97351             172             2      0.911531     0.714967   \n",
       "1094  25920   78911             123             2      2.337692     1.159702   \n",
       "986   25920  125919               6             2     -1.382817     0.356283   \n",
       "5000  26340   30781             125             2      2.316448     1.273985   \n",
       "1933  25990   53483              21             2     -2.455953     0.406044   \n",
       "4934  26340   23365              57             2     -1.606926     0.690241   \n",
       "2456  26030   51043              20             2     -9.424778    -9.424778   \n",
       "\n",
       "        aafit_lambda        aafit_beta  bbfit_azimut  bbfit_zenit  \\\n",
       "2076  -6.45441076961   0.0154777204448     -9.424778     0.412248   \n",
       "1114  -6.34336377532    0.123222929322      2.531700     1.229617   \n",
       "3562  -5.90871984937   0.0261208876628      2.246594     1.483662   \n",
       "1699  -5.58818350355  0.00798197815014     -9.424778     0.656172   \n",
       "1094   -6.2470896742   0.0407885708822     -9.424778     1.184103   \n",
       "986   -5.50046034996   0.0136745911615     -9.424778     0.256969   \n",
       "5000  -5.52610126548   0.0108518854219      2.323447     1.246598   \n",
       "1933  -5.31446152589  0.00926182047559     -2.382000     0.393877   \n",
       "4934   -4.8832394884  0.00826000187661     -9.424778     0.619391   \n",
       "2456               1                -1     -0.685443     1.499144   \n",
       "\n",
       "      bbfit_quality  muon_azimut  muon_zenit  muon_energy  \n",
       "2076       1.313463     0.026999    0.675214      24.8090  \n",
       "1114       2.934493    -2.463634    0.349742     333.7690  \n",
       "3562       1.865748     2.011759    1.499025    7039.0700  \n",
       "1699       0.960881     1.071556    0.725642    7939.4800  \n",
       "1094       6.608104     2.625332    1.755859     207.8210  \n",
       "986        0.645198    -0.352943    0.291665      19.8327  \n",
       "5000       1.186672     2.305526    1.269835     215.0780  \n",
       "1933       0.553995    -1.988018    0.397162     102.2160  \n",
       "4934       1.577757    -1.613415    0.698633      57.1997  \n",
       "2456       4.044593    -2.203849    2.262202    9111.8300  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PRUEBAS... BORRAR ESTA CELDA AL FINAL\n",
    "\n",
    "#Viendo como quedó el dataframe\n",
    "print(\"El número de filas del dataframe es:\", df_data1.shape[0])\n",
    "\n",
    "print(\"Una muestra de las filas y la data en ellas\")\n",
    "\n",
    "df_data1.sample(10)\n",
    "\n",
    "#df_data1.iloc[0:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Una vez que tenemos el dataframe con toda la data relevante de aafit y bbfit\n",
    "## debemos guardar esta data a disco\n",
    "\n",
    "outputpath = \"Z:\\MASTER INT. ARTIFICIAL\\TFM_DATA\\CLEANDATA\\\\\"\n",
    "    \n",
    "df_data1.to_csv (outputpath+\"data_aafit_bbfit_muon\"+\".csv\", index = None)#, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EL SIGUIENTE CÓDIGO NO ES NECESARIO PERO LO DEJÉ COMO EVIDENCIA DE LO QUE HABÍA ESTADO HACIENDO INICIALMENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "####  ESTE CODIGO CONTIENE EL PRIMER ALGORITMO QUE GENERÉ PARA OBTENER LA DATA DE      ###\n",
    "####  UN ARCHIVO CSV YA CON TRATAMIENTO \"INICIAL\", ES DECIR SIN LINEAS VACIAS Y OTRAS  ### \n",
    "####          ESTABA DIVIDIDO EN DOS CELDAS POR TODO EL TESTING QUE HICE               ###\n",
    "##########################################################################################\n",
    "\n",
    "    ####  #####  #####  #####  #####\n",
    "    ##    ####   ####   #   #  ####\n",
    "    ####  #   #  #   #  #####  #   #\n",
    "    \n",
    "# -->ESTE ALGORITMO TUVO UN FALLO FUNDAMENTAL... NO TOMABA EN CUENTA QUE HAY ARCHIVOS QUE NO TIENEN DATA DE AAFIT\n",
    "# -->Sin embargo me sirvió como base primaria para generar el adecuado (2da. celda de arriba a abajo de este notebook)\n",
    "\n",
    "file = csv_path+csvarr[1]\n",
    "print(\"El archivo trabajando es: \",file)\n",
    "data = pd.read_csv(file, header=None) # Dataframe del archivo en tratamiento\n",
    "ind_startev = [];ind_runid = [];ind_weights = [];ind_muon = []\n",
    "ind_aafit = [];ind_bbfit = [];ind_bb_selp = [];ind_endev = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    tempstr = data[0][i]\n",
    "    if \"start_event\" in tempstr:\n",
    "        ind_startev.append(i)\n",
    "    if \"UTC\" in tempstr:\n",
    "        ind_runid.append(i)\n",
    "    if \"weights\" in tempstr:\n",
    "        ind_weights.append(i)\n",
    "    if \"muon\" in tempstr:\n",
    "        ind_muon.append(i)\n",
    "    if \"aafit\" in tempstr:\n",
    "        ind_aafit.append(i)\n",
    "    if \"bbfit\" in tempstr:\n",
    "        ind_bbfit.append(i)\n",
    "    if \"selected\" in tempstr:\n",
    "        ind_bb_selp.append(i)\n",
    "    if \"end_event\" in tempstr:\n",
    "        ind_endev.append(i)\n",
    "\n",
    "####### YA QUE LOGRE GENERAR EL DATAFRAME PARA LOS DATOS DE AAFIT Y BBBFIT DE UN SOLO EVENTO,\n",
    "####### AHORA LO HARÉ PARA TODOS LOS EVENTOS EN EL MISMO ARCHIVO\n",
    "####### CODIGO PARA OBTENER LA DATA AAFIT, BBFIT, TRANSFORMACIONES Y OTROS PARA EL DATAFRAME\n",
    "\n",
    "#Como el runid es identico para todos los datos en un mismo archivo, uso el primero que aparece en el dataframe\n",
    "runID = int(list(str(data[0][ind_runid[0]]).split(\" \"))[0])\n",
    "\n",
    "#Igual como el interactionID es el mismo para todos, asigno 1 si el archivo es \"numu\" y 2 si es \"anumu\"\n",
    "if \"anumu\" in str(file):\n",
    "    interactionID = 2\n",
    "else:\n",
    "    interactionID = 1\n",
    "    \n",
    "#Se requiere un dataframe donde iremos guardando cada fila de data obtenida\n",
    "columnas = ['runID','frameID','trigger_counter','interactionID','aafit_azimut','aafit_zenit',\n",
    "            'aafit_lambda','aafit_beta','bbfit_azimut','bbfit_zenit','bbfit_quality']\n",
    "df_data1 = pd.DataFrame(columns=columnas)\n",
    "\n",
    "#Ahora generamos un bucle para recorrer todo el archivo y usamos los indices\n",
    "for i in range(len(ind_startev)):\n",
    "    #Codigo para obtener los demas datos por cada evento y despues asignarlo a los hits\n",
    "    #Divido la cadena en los valores que la componen para después extraer frameid y trigger_counter\n",
    "    temprunid = list(data[0][ind_runid[i]].split(\" \"))\n",
    "    tempmuon = list(data[0][ind_muon[i]].split(\" \"))\n",
    "    tempaafit = list(data[0][ind_aafit[i]].split(\" \"))\n",
    "    tempbbfit = list(data[0][ind_bbfit[i]].split(\" \"))\n",
    "    #Extrayendo las variables frameid, trigger_counter de este renglon---> esta data si cambia ojo!!\n",
    "    frameID = temprunid[1]; trigger_counter = temprunid [2]\n",
    "    #Obteniendo y generando Datos para aafit\n",
    "    aafit_azimut = math.atan2(float(tempaafit[3]),float(tempaafit[2]))\n",
    "    aafit_zenit = math.acos(float(tempaafit[4]))\n",
    "    aafit_lambda = tempaafit[-2]\n",
    "    aafit_beta = tempaafit [-1]\n",
    "    #Obteniendo y generando Datos para bbfit\n",
    "    X = float(tempbbfit[2]); Y = float(tempbbfit[3]); Z = float(tempbbfit[4])\n",
    "    #Hay que verificar si X o Y son nan y asignar el valor de bbfit_azimut\n",
    "    if math.isnan(X):   bbfit_azimut = -3*math.pi\n",
    "    elif math.isnan(Y): bbfit_azimut = -3*math.pi\n",
    "    else: bbfit_azimut = math.atan2(Y,X)\n",
    "    bbfit_zenit = math.acos(Z)\n",
    "    bbfit_quality = float(tempbbfit[-1]) \n",
    "    #Añadimos la data obtenida y la generada al dataframe\n",
    "    renglon = [runID, frameID, trigger_counter, interactionID,aafit_azimut, aafit_zenit,\n",
    "               aafit_lambda,aafit_beta, bbfit_azimut,bbfit_zenit,bbfit_quality]\n",
    "    df_data1.loc[i] = renglon\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
